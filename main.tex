\documentclass[final,a4paper,openany,12pt]{mwbk}
\pdfminorversion=7
\usepackage{polski}
\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{tgtermes}
\usepackage[T1]{fontenc}
\input glyphtounicode
\pdfgentounicode=1
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{bbm}
\usepackage{tikz}
\usetikzlibrary{automata, positioning, arrows.meta}
\usepackage{minted}
\usepackage{amsthm}
\usepackage{gensymb}
\usepackage{mathrsfs}
\usepackage{biblatex}
\usepackage{csquotes}
\usepackage{graphicx}
\usepackage{float}
\addbibresource{ref.bib}

% ustawienia do wydruku dwustronnego z uwzględnieniem dodatkowego miejsca na zszycie
\setlength{\oddsidemargin}{0.46cm} %margines nieparzysty
\setlength{\evensidemargin}{-0.54cm} %margines parzysty
\setlength{\textwidth}{16cm} %szerokość tekstu na stronie
\linespread{1.1} % lekkie zwiększenie odstępu między liniami, żeby tekst nie był taki ścisły, ponieważ
% Odstęp pojedynczej interlinii nie jest komfortowy, kiedy trzeba czytać strony A4
% koniec ustawień
\fontfamily{lmr}\selectfont

\begin{document}
\newtheorem{Tw}{Twierdzenie}
\newtheorem{Def}{Definicja}
\newtheorem{Prz}{Przykład}
\newtheorem{Dow}{Dowód}
\newtheorem{Ozn}{Oznaczenie}
% instrukcja poniżej: wybór czcionki z pakietu 'lmodern' jako domyślnej
\fontfamily{lmr}\selectfont % wybór czcionki "Latin Modern Roman"

\begin{titlepage}
\vspace{-0.5cm}

\renewcommand{\arraystretch}{1.3} % zwiększamy odległość między wierszami na stronie tytułowej

\begin{center}
{\footnotesize
\begin{tabular}{c}
UNIWERSYTET KARDYNAŁA STEFANA WYSZYŃSKIEGO\\
W WARSZAWIE\\
\end{tabular}
}
\vspace{2.5cm}

{\footnotesize
\begin{tabular}{c}
WYDZIAŁ MATEMATYCZNO-PRZYRODNICZY\\
SZKOŁA NAUK ŚCISŁYCH\\
\end{tabular}
}
\vspace{2.7cm}

\renewcommand{\arraystretch}{1.5} % zwiększamy odległość między wierszami

{\normalsize
\begin{tabular}{c}
Korneliusz Pogorzelczyk\\

109204\\

matematyka\\
\end{tabular}
}

\vspace{2.3cm}

{\large
\begin{tabular}{c}
Łańcuchy Markowa
\end{tabular}
}

\end{center}
\vspace{4cm}

\hspace{6cm}
\begin{tabular}{l}
Praca licencjacka\\

Promotor:\\

dr Tomasz Rogala
\end{tabular}

\vspace{3.5cm}

{\centering

{\small
\begin{tabular}{c}
{WARSZAWA, 2025}\\
\end{tabular}
}

}

\renewcommand{\arraystretch}{1} % przywracamy domyślną odległość miedzy wierszami na następnych stronach

\end{titlepage}

\chapter{Wstęp}

\section{Motywacja i wprowadzenie}

W dzisiejszym świecie, gdzie losowość i niepewność odgrywają kluczową rolę w wielu obszarach nauki i techniki, procesy stochastyczne stanowią fundament matematycznego opisu zjawisk losowych. Spośród różnorodnych rodzajów procesów stochastycznych łańcuchy Markowa wyróżniają się szczególną elegancją matematyczną oraz szerokim wachlarzem zastosowań praktycznych.

Łańcuchy Markowa, nazwane na cześć rosyjskiego matematyka Andrieja Markowa, który wprowadził to pojęcie na początku XX wieku, charakteryzują się szczególną własnością: przyszły stan procesu zależy wyłącznie od stanu obecnego, a nie od stanów poprzednich. Ta własność (zwana brakiem pamięci lub własnością Markowa) znacząco upraszcza analizę matematyczną tych procesów, jednocześnie zachowując ich zdolność do modelowania złożonych zjawisk rzeczywistych.

Zastosowania łańcuchów Markowa są niezwykle różnorodne i obejmują takie dziedziny jak:
\begin{itemize}
    \item Finanse i ekonomia -- modelowanie rynków finansowych, ocena ryzyka kredytowego, teoria podejmowania decyzji;
    \item Biologia i medycyna -- modelowanie rozprzestrzeniania się chorób, analiza sekwencji DNA, badanie procesów ewolucyjnych;
    \item Fizyka -- opis układów cząstek, mechanika statystyczna, procesy dyfuzji;
    \item Informatyka -- algorytmy uczenia maszynowego, generowanie tekstu, kompresja danych, metoda Monte Carlo oparta na łańcuchach Markowa.
\end{itemize}

W niniejszej pracy skupimy się na łańcuchach Markowa w czasie dyskretnym, które stanowią fundamentalny i intuicyjny wariant tej klasy procesów stochastycznych. Zbadamy ich podstawowe własności teoretyczne oraz przedstawimy praktyczne zastosowanie, ilustrując teorię konkretnym przykładem implementacji.

\section{Cele i zakres pracy}

Głównym celem niniejszej pracy jest przedstawienie teorii łańcuchów Markowa w czasie dyskretnym oraz demonstracja ich praktycznego zastosowania. W szczególności, praca stawia sobie następujące cele:

\begin{enumerate}
    \item Zaprezentowanie niezbędnych podstaw rachunku prawdopodobieństwa, stanowiących fundament teoretyczny dla zrozumienia łańcuchów Markowa.
    
    \item Wprowadzenie formalnej definicji łańcuchów Markowa w czasie dyskretnym oraz szczegółowa analiza ich kluczowych własności, ze szczególnym uwzględnieniem:
    \begin{itemize}
        \item Klasyfikacji stanów (stany przejściowe, pochłaniające, okresowe i ergodyczne),
        \item Zachowania długoterminowego (rozkłady stacjonarne, ergodyczność),
        \item Czasów pierwszego przejścia i powrotu do stanów.
    \end{itemize}
    
\end{enumerate}

Zakres pracy ogranicza się do łańcuchów Markowa w czasie dyskretnym, co oznacza, że stan procesu zmienia się w dyskretnych chwilach czasowych (krokach). Główny nacisk położony zostanie na łańcuchy jednorodne (dla których prawdopodobieństwa przejścia nie zależą od czasu).

Praca koncentruje się na podstawowych koncepcjach i własnościach łańcuchów Markowa, stanowiąc wprowadzenie do tego obszaru teorii procesów stochastycznych. Bardziej zaawansowane zagadnienia, takie jak uogólnienia do czasu ciągłego czy łańcuchy Markowa wyższego rzędu, wykraczają poza zakres niniejszej pracy.

\chapter{Wybrane zagadnienia rachunku prawdopodobieństwa}

\section{Przestrzenie probabilistyczne}

Podstawą formalnego opisu zjawisk losowych jest pojęcie przestrzeni probabilistycznej. Jest to matematyczna struktura, która pozwala na precyzyjne definiowanie zdarzeń i przypisywanie im prawdopodobieństw.

\begin{Def}[Doświadczenie losowe]
Doświadczeniem losowym nazywamy procedurę, którą możemy wielokrotnie powtarzać w identycznych
warunkach i której wyników nie da się przewidzieć z pewnością
przed jej wykonaniem, lecz można opisać je probabilistycznie.
\end{Def}


\begin{Def}[Przestrzeń zdarzeń elementarnych $\Omega$] Jest to zbiór wszystkich możliwych, wzajemnie wykluczających się wyników danego doświadczenia losowego. Elementy zbioru $\Omega$ nazywamy zdarzeniami elementarnymi.
\end{Def}
\begin{Prz}
    Dla jednokrotnego rzutu sześcienną kostką do gry, $\Omega = \{1, 2, 3, 4, 5, 6\}$.
\end{Prz}
\begin{Prz}
    Dla pomiaru czasu życia żarówki $\Omega = [0, \infty)$ (lub $\mathbb{R}_{\ge 0}$), czyli zbiór wszystkich nieujemnych liczb rzeczywistych.
\end{Prz}

\begin{Ozn}
Niech X będzie zbiorem. Przez $\mathcal{P}(X)$ będziemy oznaczać rodzinę wszystkich podzbiorów zbioru X.
\end{Ozn}

\begin{Def}[$\sigma$-ciało]
Niech $\Omega$ będzie niepustym zbiorem.  Zbiór
$\mathcal{F}\subseteq \mathcal{P}(\Omega)$ nazywamy \emph{$\sigma$-ciałem}
na~$\Omega$, jeżeli spełnia warunki:
    \begin{enumerate}
        \item $\Omega \in \mathcal{F}$ (cała przestrzeń zdarzeń elementarnych jest zdarzeniem).
        \item Jeżeli $A \in \mathcal{F}$, to $\Omega \setminus A \in \mathcal{F}$ (jeśli $A$ jest zdarzeniem to jego dopełnienie również jest zdarzeniem).
        \item Jeżeli $A_1, A_2, \dots$ jest przeliczalnym ciągiem zdarzeń z $\mathcal{F}$ (tzn. $A_i \in \mathcal{F}$ dla $i=1, 2, \dots$), to ich suma $\bigcup_{i=1}^{\infty} A_i \in \mathcal{F}$ jest zdarzeniem.
    \end{enumerate}
    Elementy $\sigma$-ciała $\mathcal{F}$ nazywamy zdarzeniami.
\end{Def}
\begin{Prz}
            Dla rzutu kostką $\mathcal{F}$ może być zbiorem wszystkich możliwych podzbiorów $\Omega$, np. zdarzenie "wypadła parzysta liczba oczek" to $\{2,4,6\}$
\end{Prz}

\begin{Def}[Przestrzeń mierzalna]
Parę $\bigl(\Omega,\mathcal{F}\bigr)$, gdzie $\Omega$ jest zbiorem,
zaś $\mathcal{F}$ –~$\sigma$-ciałem na~$\Omega$, nazywamy
przestrzenią mierzalną.
\end{Def}

\begin{Def}[Miara prawdopodobieństwa P]
Jest to funkcja $P: \mathcal{F} \to [0, 1]$, przypisująca każdemu zdarzeniu $A \in \mathcal{F}$ liczbę $P(A)$, zwaną prawdopodobieństwem zdarzenia $A$, która spełnia następujące aksjomaty (aksjomaty Kołmogorowa):
\begin{enumerate}
    \item $P(A) \ge 0$ dla każdego $A \in \mathcal{F}$.
    \item $P(\Omega) = 1$.
    \item Dla dowolnego ciągu parami rozłącznych zdarzeń $A_1, A_2, \dots$ $\in \mathcal{F}$ (tzn. $A_i \cap A_j = \emptyset$ dla $i \neq j$), zachodzi:
    $$P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i) \quad (\text{przeliczalna addytywność})$$
\end{enumerate}
\end{Def}

\begin{Def}[Przestrzeń probabilistyczna]
    Trójkę $(\Omega, \mathcal{F}, P)$ nazywamy \textbf{przestrzenią probabilistyczną}.
\end{Def}

\begin{Prz}
  \[
    \Omega=\{1,2,3,4,5\},\qquad
    \mathcal{F}=\mathcal{P}(\Omega),\qquad
    \mathbb{P}(A)=\frac{|A|}{5},\; A\subseteq\Omega.
  \]
\end{Prz}

Rozpatrujemy rosyjską ruletkę z pięciokomorowym rewolwerem, w którym
jedna z komór (niech będzie to ~\(\omega=1\)) zawiera nabój.
Cylinder zostaje zakręcony, a więc po zatrzymaniu dowolna komora
\(\omega\in\{1,\dots,5\}\) może znaleźć się pod kurkiem
z jednakowym prawdopodobieństwem.

\begin{itemize}
  \item \emph{Przestrzeń zdarzeń elementarnych} \(\Omega\) indeksuje komorę,
        która ustawi się w pozycji strzału.
  \item \emph{Zbiór zdarzeń} \(\mathcal{F}=\mathcal{P}(\Omega)\)
        to wszystkie możliwe podzbiory \(\Omega\),
        np.\ zdarzenie śmiertelne to \(\{1\}\),
        a zdarzenie „przeżycie” to \(\{2,3,4,5\}\).
  \item \emph{Miara prawdopodobieństwa} \(\mathbb{P}\) jest jednostajna,
        gdyż cylinder kręci się swobodnie, dlatego
        \[
          \mathbb{P}(\{1\})=\frac15, \qquad
          \mathbb{P}(\{2,3,4,5\})=\frac45.
        \]
\end{itemize}

Tak zdefiniowana trójka \((\Omega,\mathcal{F},\mathbb{P})\)
spełnia aksjomaty Kołmogorowa i stanowi pełny opis tego doświadczenia losowego.


\vspace{3mm}

\subsection{Podstawowe własności miary prawdopodobieństwa}

Niech $(\Omega, \mathcal{F}, P)$ będzie przestrzenią probabilistyczną, gdzie:
\begin{itemize}
    \item $\Omega$ -- przestrzeń zdarzeń elementarnych
    \item $\mathcal{F}$ -- $\sigma$-ciało podzbiorów $\Omega$ 
    \item $P: \mathcal{F} \to [0,1]$ -- miara prawdopodobieństwa
\end{itemize}

\begin{Tw}[Zbiór pusty należy do $\mathcal{F}$]
$\emptyset \in \mathcal{F}$
\end{Tw}

\begin{Dow}
Ponieważ $\mathcal{F}$ jest $\sigma$-ciałem, to $\Omega \in \mathcal{F}$. Z definicji $\sigma$-ciała wynika również, że jeśli $A \in \mathcal{F}$, to $A^c \in \mathcal{F}$ (zamknięcie na dopełnienie).

Zatem: $\emptyset = \Omega^c \in \mathcal{F}$.
\end{Dow}

\begin{Tw}[Zamknięcie na przeliczalne przecięcia]
Jeżeli zbiory $A_1, A_2, A_3, \ldots \in \mathcal{F}$, to $\displaystyle\bigcap_{i=1}^{\infty} A_i \in \mathcal{F}$
\end{Tw}

\begin{Dow}
Niech $(A_i)_{i\in\mathbb{N}} \subset \mathcal{F}$, gdzie $A_i^c$ oznacza dopełnienie zbioru $A_i$.

\begin{enumerate}
    \item Ponieważ $\mathcal{F}$ jest $\sigma$-ciałem, z $A_i \in \mathcal{F}$ wynika $A_i^c \in \mathcal{F}$ dla każdego $i$ (zamknięcie na dopełnienia).
    
    \item Znów z definicji $\sigma$-ciała otrzymujemy:
    $$\bigcup_{i=1}^{\infty} A_i^c \in \mathcal{F}$$
    (zamknięcie na przeliczalne sumy).
    
    \item Skoro $\mathcal{F}$ jest zamknięte na dopełnienie, to:
    $$\left(\bigcup_{i=1}^{\infty} A_i^c\right)^c \in \mathcal{F}$$
    
    \item Z praw de Morgana mamy:
    $$\left(\bigcup_{i=1}^{\infty} A_i^c\right)^c = \bigcap_{i=1}^{\infty} A_i$$
\end{enumerate}

Zatem $\displaystyle\bigcap_{i=1}^{\infty} A_i \in \mathcal{F}$.
\end{Dow}

\begin{Tw}[Prawdopodobieństwo zbioru pustego]
$P(\emptyset) = 0$
\end{Tw}

\begin{Dow}
Rozważmy przeliczalną sumę zbiorów pustych:
$$P(\emptyset) = P\left(\bigcup_{i=1}^{\infty} \emptyset\right)$$

Ponieważ zbiory $\emptyset$ są parami rozłączne, z $\sigma$-addytywności miary $P$ wynika:
$$P\left(\bigcup_{i=1}^{\infty} \emptyset\right) = \sum_{i=1}^{\infty} P(\emptyset)$$

Jeśli $P(\emptyset) = a > 0$, to szereg $\sum_{i=1}^{\infty} a$ byłby rozbieżny do $+\infty$, co przeczy temu, że $P(\emptyset) \in [0,1]$.

Zatem $P(\emptyset) = 0$.
\end{Dow}

\begin{Tw}[Skończona addytywność]
Jeżeli zbiory $A_1, A_2, \ldots, A_n \in \mathcal{F}$ oraz $A_i \cap A_j = \emptyset$ dla $i \neq j$, to:
$$P\left(\bigcup_{i=1}^{n} A_i\right) = \sum_{i=1}^{n} P(A_i)$$
\end{Tw}

\begin{Dow}
Definiujemy ciąg $(B_i)_{i=1}^{\infty}$ następująco:
\begin{itemize}
    \item $B_i = A_i$ dla $i \leq n$
    \item $B_i = \emptyset$ dla $i > n$
\end{itemize}

Zbiory $B_i$ są parami rozłączne i $\displaystyle\bigcup_{i=1}^{n} A_i = \bigcup_{i=1}^{\infty} B_i$.

Z $\sigma$-addytywności:
$$P\left(\bigcup_{i=1}^{n} A_i\right) = P\left(\bigcup_{i=1}^{\infty} B_i\right) = \sum_{i=1}^{\infty} P(B_i) = \sum_{i=1}^{n} P(A_i) + \sum_{i=n+1}^{\infty} P(\emptyset)$$

Ponieważ $P(\emptyset) = 0$, otrzymujemy:
$$P\left(\bigcup_{i=1}^{n} A_i\right) = \sum_{i=1}^{n} P(A_i)$$
\end{Dow}

\begin{Tw}[Monotoniczność względem różnicy]
Jeżeli $A$ i $B$ są takimi zdarzeniami, że $A \subset B$, to:
$$P(B) = P(A) + P(B \setminus A)$$
\end{Tw}

\begin{Dow}
Jeśli $A \subset B$, to można przedstawić $B$ jako sumę rozłączną:
$$B = A \cup (B \setminus A)$$

Ponieważ $A \cap (B \setminus A) = \emptyset$, z skończonej addytywności:
$$P(B) = P(A \cup (B \setminus A)) = P(A) + P(B \setminus A)$$
\end{Dow}

\begin{Tw}[Prawdopodobieństwo dopełnienia]
Dla każdego zdarzenia $A$:
$$P(\Omega \setminus A) = 1 - P(A)$$
\end{Tw}

\begin{Dow}
Mamy $\Omega = A \cup (\Omega \setminus A)$ oraz $A \cap (\Omega \setminus A) = \emptyset$.

Z skończonej addytywności:
$$P(\Omega) = P(A) + P(\Omega \setminus A)$$

Ponieważ $P(\Omega) = 1$ (z definicji miary prawdopodobieństwa):
$$1 = P(A) + P(\Omega \setminus A)$$

Stąd: $P(\Omega \setminus A) = 1 - P(A)$
\end{Dow}

\begin{Tw}[Monotoniczność miary]
Jeżeli $A$ i $B$ są takimi zdarzeniami, że $A \subset B$, to:
$$P(A) \leq P(B)$$
\end{Tw}

\begin{Dow}
Z Twierdzenia 5 wiemy, że jeśli $A \subset B$, to:
$$P(B) = P(A) + P(B \setminus A)$$

Ponieważ $P(B \setminus A) \geq 0$ (prawdopodobieństwo jest nieujemne), otrzymujemy:
$$P(B) = P(A) + P(B \setminus A) \geq P(A)$$

Zatem $P(A) \leq P(B)$.
\end{Dow}

\begin{Tw}[Zasada włączeń-wyłączeń dla dwóch zbiorów]
Dla dowolnych zdarzeń $A$ i $B$:
$$P(A \cup B) = P(A) + P(B) - P(A \cap B)$$
\end{Tw}

\begin{Dow}
Zauważmy, że
\[
A\cup B = (A\setminus B)\;\cup\;(B\setminus A)\;\cup\;(A\cap B),
\]
gdzie te trzy zbiory są parami rozłączne. Z własności skończonej addytywności mamy:
\[
P(A\cup B)
= P(A\setminus B) + P(B\setminus A) + P(A\cap B).
\]

Ponadto:
\[
A = (A\setminus B)\cup(A\cap B)
\quad\Longrightarrow\quad
P(A) = P(A\setminus B) + P(A\cap B),
\]
\[
B = (B\setminus A)\cup(A\cap B)
\quad\Longrightarrow\quad
P(B) = P(B\setminus A) + P(A\cap B).
\]
Stąd:
\[
P(A\setminus B) = P(A) - P(A\cap B),
\qquad
P(B\setminus A) = P(B) - P(A\cap B).
\]

Podstawiając do wzoru na \(P(A\cup B)\):
\[
\begin{aligned}
P(A\cup B)
&= \bigl[P(A) - P(A\cap B)\bigr]
  + \bigl[P(B) - P(A\cap B)\bigr]
  + P(A\cap B)\\
&= P(A) + P(B) - P(A\cap B).
\end{aligned}
\]
\end{Dow}


\section{Prawdopodobieństwo warunkowe i niezależność}
Często interesuje nas prawdopodobieństwo zajścia jednego zdarzenia pod warunkiem, że zaszło inne zdarzenie. Pojęcie to jest sformalizowane przez prawdopodobieństwo warunkowe.

\begin{Def}[Prawdopodobieństwo warunkowe]
    Niech $(\Omega, \mathcal{F}, P)$ będzie przestrzenią probabilistyczną i niech $A, B \in \mathcal{F}$ będą dwoma zdarzeniami, przy czym $P(B) > 0$. Prawdopodobieństwo warunkowe zdarzenia $A$ pod warunkiem zajścia zdarzenia $B$ określamy wzorem:
    $$P(A|B) = \frac{P(A \cap B)}{P(B)}$$
\end{Def}


Prawdopodobieństwo warunkowe $P(A|B)$ mówi nam, jak zmienia się szansa na zajście zdarzenia $A$, gdy posiadamy informację, że zdarzenie $B$ już miało miejsce. Przestrzeń zdarzeń elementarnych zostaje ograniczona do tych, które sprzyjają zdarzeniu $B$.


\begin{Tw}[Wzór na prawdopodobieństwo całkowite]
Dana jest przestrzeń probabilistyczna $(\Omega, \mathcal{F}, P)$ oraz zdarzenia $B_1, \dots, B_n \in \mathcal{F}$ spełniające warunki:
\begin{enumerate}
    \item[(i)] $P(B_i) > 0$ dla każdego $i = 1, \dots, n$,
    \item[(ii)] $B_i \cap B_j = \emptyset$ dla wszystkich $i \neq j$,
    \item[(iii)] $B_1 \cup \dots \cup B_n = \Omega$.
\end{enumerate}
Wtedy dla każdego zdarzenia $A \in \mathcal{F}$ zachodzi wzór:
\[
P(A) = \sum_{i=1}^{n} P(A|B_i)P(B_i).
\]
\end{Tw}
\begin{Dow}
    Ponieważ $A = A \cap \Omega = A \cap (\bigcup_{i=1}^{n} B_i) = \bigcup_{i=1}^{n} (A \cap B_i)$, mamy
\[
P(A) = \sum_{i=1}^{n} P(A \cap B_i) = \sum_{i=1}^{n} P(A|B_i)P(B_i).
\]
\end{Dow}

\begin{Prz}
Mamy trzy urny. W pierwszej urnie znajdują się 2 białe kule i 3 czarne. W drugiej 4 białe i 1 czarna, a w trzeciej 1 biała i 4 czarne. Losujemy jedną urnę, a następnie z niej jedną kulę. Jakie jest prawdopodobieństwo wylosowania białej kuli?

Niech $U_1, U_2, U_3$ oznaczają zdarzenia polegające na wyborze odpowiednio urny pierwszej, drugiej i trzeciej. Zdarzenia te stanowią warunki (pełen układ zdarzeń). Niech $A$ będzie zdarzeniem polegającym na wylosowaniu białej kuli.

Prawdopodobieństwo wyboru każdej z urn jest takie samo :
\[ P(U_1) = P(U_2) = P(U_3) = \frac{1}{3} \]

Prawdopodobieństwa warunkowe wylosowania białej kuli pod warunkiem wyboru konkretnej urny wynoszą:
\begin{itemize}
    \item $P(A|U_1) = \frac{2}{2+3} = \frac{2}{5}$
    \item $P(A|U_2) = \frac{4}{4+1} = \frac{4}{5}$
    \item $P(A|U_3) = \frac{1}{1+4} = \frac{1}{5}$
\end{itemize}

Stosując wzór na prawdopodobieństwo całkowite obliczamy $P(A)$:
\begin{align*}
P(A) &= P(A|U_1)P(U_1) + P(A|U_2)P(U_2) + P(A|U_3)P(U_3) \\
&= \frac{2}{5} \cdot \frac{1}{3} + \frac{4}{5} \cdot \frac{1}{3} + \frac{1}{5} \cdot \frac{1}{3} \\
&= \frac{1}{3} \left( \frac{2}{5} + \frac{4}{5} + \frac{1}{5} \right) \\
&= \frac{1}{3} \cdot \frac{7}{5} = \frac{7}{15}
\end{align*}

Wobec tego prawdopodobieństwo całkowite wylosowania białej kuli wynosi $\frac{7}{15}$.
\end{Prz}

\begin{Tw}[Wzór Bayesa]
Przy założeniach wzoru na prawdopodobieństwo całkowite zachodzi następująca równość:
\[
P(B_k|A) = \frac{P(A|B_k)P(B_k)}{\sum_{i=1}^{n} P(A|B_i)P(B_i)}
\]
dla każdego $k=1, \dots, n$.
\end{Tw}

\begin{Dow}
 Dowód wynika bezpośrednio z definicji prawdopodobieństwa warunkowego. Dla zdarzeń $A$ i $B_k$, gdzie $P(A) > 0$ mamy:
\[
P(B_k|A) = \frac{P(B_k \cap A)}{P(A)}
\]
Licznik $P(B_k \cap A)$ możemy rozpisać korzystając z definicji prawdopodobieństwa warunkowego (zakładamy, że $P(B_k) > 0$):
\[
P(A|B_k) = \frac{P(A \cap B_k)}{P(B_k)} \implies P(A \cap B_k) = P(A|B_k)P(B_k)
\]
Mianownik $P(A)$ rozpisujemy ze wzoru na prawdopodobieństwo całkowite, zakładając, że zbiory $\{B_i\}_{i=1}^n$ tworzą rozbicie przestrzeni $\Omega$:
\[
P(A) = \sum_{i=1}^{n} P(A|B_i)P(B_i)
\]
Podstawiając oba wyrażenia do początkowej definicji otrzymujemy tezę twierdzenia:
\[
P(B_k|A) = \frac{P(A|B_k)P(B_k)}{\sum_{i=1}^{n} P(A|B_i)P(B_i)}
\]   
\end{Dow}

Wzór Bayesa pozwala obliczyć prawdopodobieństwo "przyczyny" ($B_k$) na podstawie zaobserwowanego "skutku" ($A$). Innymi słowy, pozwala zaktualizować nasze przekonanie o prawdopodobieństwie zajścia zdarzenia $B_k$ po uzyskaniu nowej informacji, że zaszło zdarzenie $A$, uzyskując prawdopodobieństwo a posteriori $P(B_k|A)$.

\begin{Def}[Niezależność zdarzeń]
Niech $(\Omega, \mathcal{F}, P)$ będzie przestrzenią probabilistyczną. Niech $A, B \in \mathcal{F}$. 
$A, B$ są niezależne $\iff P(A \cap B) = P(A) \cdot P(B) $
\end{Def}

Zauważmy, że gdy $P(A) > 0$ mamy natychmiastową równoważność:
\begin{center}
$A, B$ są niezależne $\iff P(B|A) = P(B)$.
\end{center}

\begin{Prz}
    Rzucając dwiema kostkami łatwo sprawdzić, że:
\begin{itemize}
    \item Niezależnymi zdarzeniami są zdarzenia $A, B$: $A$ – na pierwszej kostce wypadła „4", $B$ – na drugiej kostce wypadła liczba pierwsza.
    \item Zależnymi zdarzeniami są zdarzenia $A, B$: $A$ – suma oczek na kostkach jest $\ge 8$, $B$ – na drugiej kostce wypadła „6".
    \item Zależnymi zdarzeniami są każde dwa zdarzenia rozłączne $A, B$, o ile $P(A)P(B) > 0$.
\end{itemize}
\end{Prz}

\begin{Def}
 Zdarzenia $A_1, \dots, A_n$ są niezależne $\iff$ dla każdego podciągu $A_{k_1}, \dots, A_{k_j}$ zachodzi:
\[ P(A_{k_1} \cap \dots \cap A_{k_j}) = P(A_{k_1}) \cdot \dots \cdot P(A_{k_j}). \]
Zdarzenia $A_1, A_2, A_3, \dots$ są niezależne $\iff$\ dla każdego $n \ge 2$ zdarzenia $A_1, \dots, A_n$ są niezależne. 
\end{Def}

\section{Zmienne losowe}
Zamiast bezpośrednio operować na zdarzeniach, często wygodniej jest przypisać wynikom doświadczenia losowego wartości liczbowe za pomocą zmiennych losowych.

\begin{Def}[$\sigma$-ciało borelowskie]
  Najmniejsze $\sigma$-ciało w zbiorze $\mathbb{R}$ zawierające wszystkie przedziały otwarte nazywamy $\sigma$-ciałem borelowskim i oznaczamy przez $\mathcal{B}(\mathbb{R})$.
\end{Def}

\begin{Def}[Funkcja mierzalna]
Niech $(X,\mathcal{E})$ będzie przestrzenią mierzalną.
Funkcja
\[
f \colon (\Omega,\mathcal{F}) \longrightarrow (E,\mathcal{E})
\]jest mierzalna jeżeli
\[
\forall\, B \in \mathcal{E} \qquad
f^{-1}(B)=\{\omega \in \Omega : f(\omega) \in B\}\in\mathcal{F}.
\]
\end{Def}

\begin{Def}[Wektor losowy]
Niech $(\Omega, \mathcal{F}, P)$ będzie przestrzenią probabilistyczną.
Funkcja $X \colon \Omega \longrightarrow \mathbb{R}^n$ jest wektorem losowym, jeżeli jest ona funkcją mierzalną względem $\sigma$-algebry $\mathcal{F}$, tj.
\[
X^{-1}(B) = \{\omega \in \Omega : X(\omega) \in B\} \in \mathcal{F}
\]
dla każdego zbioru borelowskiego $B \in \mathcal{B}(\mathbb{R}^n)$.
\par\noindent
\textbf{Zmienna losowa} jest jednowymiarowym wektorem losowym ($n=1$).
\end{Def}

\begin{Def}[Rozkład wektora losowego]
Rozkład wektora losowego $X \colon \Omega \longrightarrow \mathbb{R}^n$ jest to miara probabilistyczna $P_X$ określona na $\mathcal{B}(\mathbb{R}^n)$ wzorem:
\[
P_X(B) = P(X^{-1}(B)), \quad \text{ dla } B \in \mathcal{B}(\mathbb{R}^n).
\]
Innymi słowy, $P_X(B)$ to prawdopodobieństwo, że wektor losowy $X$ przyjmie wartość ze zbioru $B$.
\end{Def}

\begin{Prz}
Rozważmy jednowymiarową zmienną losową $X$ reprezentującą sumę wyników z rzutu dwiema symetrycznymi sześciennymi kostkami do gry.
\begin{itemize}
    \item Przestrzeń zdarzeń elementarnych $\Omega$ to zbiór wszystkich możliwych par wyników $(k, l)$, gdzie $k,l \in \{1, 2, 3, 4, 5, 6\}$.
    Moc zbioru $\Omega$ wynosi $6 \times 6 = 36$. Każdy wynik $(k,l)$ ma prawdopodobieństwo $\frac{1}{36}$.
    \item Zmienna losowa $X$ jest funkcją $X(k,l) = k+l$.
    \item Możliwe wartości zmiennej losowej $X$ (sumy oczek) to liczby całkowite z przedziału $[2, 12]$.
\end{itemize}

Poniżej przedstawiono rozkład prawdopodobieństwa zmiennej losowej $X$:
\begin{align*}
P(X=2)   &= P(\{(1,1)\}) = \frac{1}{36} \\
P(X=3)   &= P(\{(1,2), (2,1)\}) = \frac{2}{36} \\
P(X=4)   &= P(\{(1,3), (2,2), (3,1)\}) = \frac{3}{36} \\
P(X=5)   &= P(\{(1,4), (2,3), (3,2), (4,1)\}) = \frac{4}{36} \\
P(X=6)   &= P(\{(1,5), (2,4), (3,3), (4,2), (5,1)\}) = \frac{5}{36} \\
P(X=7)   &= P(\{(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\}) = \frac{6}{36} \\
P(X=8)   &= P(\{(2,6), (3,5), (4,4), (5,3), (6,2)\}) = \frac{5}{36} \\
P(X=9)   &= P(\{(3,6), (4,5), (5,4), (6,3)\}) = \frac{4}{36} \\
P(X=10)  &= P(\{(4,6), (5,5), (6,4)\}) = \frac{3}{36} \\
P(X=11)  &= P(\{(5,6), (6,5)\}) = \frac{2}{36} \\
P(X=12)  &= P(\{(6,6)\}) = \frac{1}{36}
\end{align*}
Sumując wszystkie prawdopodobieństwa, otrzymujemy $\sum_{k=2}^{12} P(X=k) = \frac{36}{36} = 1$, co potwierdza, że jest to prawidłowy rozkład prawdopodobieństwa.
\end{Prz}

\begin{Def}[Niezależność zmiennych losowych]
Mówimy, że zmienne losowe $X_1, X_2, \dots, X_n$ określone na tej samej przestrzeni probabilistycznej $(\Omega, \mathcal{F}, P)$ są \textbf{niezależne}, jeżeli dla dowolnych zbiorów borelowskich $B_1, B_2, \dots, B_n \in \mathcal{B}(\mathbb{R})$ zachodzi równość:
$$
P(X_1 \in B_1, X_2 \in B_2, \dots, X_n \in B_n) = P(X_1 \in B_1) \cdot P(X_2 \in B_2) \cdot \dots \cdot P(X_n \in B_n)
$$
W przypadku dwóch zmiennych losowych $X$ i $Y$, są one niezależne, gdy dla dowolnych zbiorów borelowskich $A, B \in \mathcal{B}(\mathbb{R})$:
$$
P(X \in A, Y \in B) = P(X \in A) \cdot P(Y \in B)
$$
\end{Def}

\begin{Prz}
    Rozważmy dwukrotny rzut symetryczną kostką do gry. Przestrzeń zdarzeń elementarnych $\Omega$ składa się z 36 par $(i, j)$, gdzie $i, j \in \{1, 2, 3, 4, 5, 6\}$. Każdy wynik jest jednakowo prawdopodobny, więc $P(\{(i,j)\}) = \frac{1}{36}$.

Niech zmienna losowa $X$ oznacza wynik pierwszego rzutu, a $Y$ wynik drugiego rzutu. Zatem $X(i,j) = i$ oraz $Y(i,j) = j$.

Sprawdźmy, czy te zmienne są niezależne. Wybierzmy dowolne wartości $k, l \in \{1, 2, 3, 4, 5, 6\}$.
Zdarzenie $\{X=k, Y=l\}$ odpowiada wynikowi $(k,l)$, więc jego prawdopodobieństwo wynosi:
$$
P(X=k, Y=l) = P(\{(k,l)\}) = \frac{1}{36}
$$
Zdarzenie $\{X=k\}$ zachodzi, gdy wynikiem jest jedna z par $(k,1), (k,2), \dots, (k,6)$. Jest 6 takich par, więc:
$$
P(X=k) = \frac{6}{36} = \frac{1}{6}
$$
Analogicznie dla zmiennej $Y$:
$$
P(Y=l) = \frac{6}{36} = \frac{1}{6}
$$
Sprawdzamy warunek niezależności:
$$
P(X=k) \cdot P(Y=l) = \frac{1}{6} \cdot \frac{1}{6} = \frac{1}{36}
$$
Ponieważ $P(X=k, Y=l) = P(X=k) \cdot P(Y=l)$ dla wszystkich możliwych wartości $k$ i $l$, zmienne losowe $X$ i $Y$ są niezależne.
\end{Prz}

\chapter{Łańcuchy Markowa}

W tym rozdziale formalnie zdefiniujemy łańcuchy Markowa i zbadamy ich podstawowe właściwości.


\begin{Def}[Jednorodny łańcuch Markowa]
Niech $(\Omega,\mathcal F, P)$ będzie przestrzenią probabilistyczną, a 
$(X_n)_{n\ge 0}$ — ciągiem zmiennych losowych przyjmujących wartości w skończonym
lub przeliczalnym zbiorze stanów $S$.  
Ciąg ten nazywamy \emph{(jednorodnym) łańcuchem Markowa} wtedy i tylko wtedy, gdy
dla każdego $n\in\mathbb N$ oraz wszystkich $i_0,\ldots,i_{n-1},i,j\in S$ zachodzi
\[
  P\!\bigl(X_{n+1}=j \;\big|\;
      X_0=i_0,\ldots,X_{n-1}=i_{n-1},X_n=i\bigr)
    \;=\;
  P\!\bigl(X_{n+1}=j \mid X_n=i\bigr)
    \;=\; p_{ij},
\]
gdzie $p_{ij}$ zależą jedynie od bieżącego stanu $i$ i stanu $j$, lecz nie od $n$.
Macierz $P=(p_{ij})_{i,j\in S}$ nazywamy \emph{macierzą przejścia} łańcucha Markowa.
\end{Def}

\section{Macierz przejścia}

Macierz przejścia jest fundamentalnym narzędziem do opisu łańcuchów Markowa. Zawiera ona wszystkie informacje o prawdopodobieństwach przejścia między stanami, co pozwala na pełną charakterystykę procesu stochastycznego.

\begin{Def}[Macierz przejścia]
Niech $(X_n)_{n \geq 0}$ będzie łańcuchem Markowa ze skończonym lub przeliczalnym zbiorem stanów $S$. Macierzą przejścia nazywamy macierz $P = (p_{ij})_{i,j \in S}$, gdzie:
$$p_{ij} = P(X_{n+1} = j | X_n = i)$$
dla wszystkich $i, j \in S$ i $n \geq 0$.
\end{Def}

Macierz przejścia musi spełniać następujące warunki:
\begin{enumerate}
    \item $p_{ij} \geq 0$ dla wszystkich $i, j \in S$ (nieujemność prawdopodobieństw),
    \item $\sum_{j \in S} p_{ij} = 1$ dla wszystkich $i \in S$ (warunek normalizacji).
\end{enumerate}

Macierz spełniającą powyższe warunki nazywamy \textbf{macierzą stochastyczną}. Oznacza to, że suma elementów w każdym wierszu wynosi 1.

\begin{Prz}[Spacer losowy na prostej]
Rozważmy cząstkę poruszającą się po liczbach całkowitych $\mathbb{Z}$. W każdym kroku czasowym cząstka przesuwa się o jedną pozycję w prawo z prawdopodobieństwem $p$ lub o jedną pozycję w lewo z prawdopodobieństwem $q = 1-p$. Jest to przykład łańcucha Markowa zwanego spacerem losowym.

Dla dowolnego stanu $i \in \mathbb{Z}$ mamy:
\begin{align}
p_{i,i+1} &= p \\
p_{i,i-1} &= q = 1-p \\
p_{i,j} &= 0 \text{ dla } j \neq i-1, i+1
\end{align}

Fragment macierzy przejścia wygląda następująco:
$$P = \begin{pmatrix}
\ddots & \ddots & \ddots & \ddots & \ddots \\
\ddots & 0 & q & 0 & p & 0 & \ddots \\
\ddots & 0 & 0 & q & 0 & p & \ddots \\
\ddots & p & 0 & 0 & q & 0 & \ddots \\
\ddots & 0 & p & 0 & 0 & q & \ddots \\
\ddots & \ddots & \ddots & \ddots & \ddots
\end{pmatrix}$$
\end{Prz}

\subsection{Prawdopodobieństwa przejścia w $n$ krokach}

Często interesuje nas prawdopodobieństwo przejścia z jednego stanu do drugiego w określonej liczbie kroków.

\begin{Def}[Prawdopodobieństwa przejścia w $n$ krokach]
Dla łańcucha Markowa $(X_n)_{n \geq 0}$ definiujemy:
$$p_{ij}^{(n)} = P(X_{m+n} = j | X_m = i)$$
dla $m, n \geq 0$ i $i, j \in S$. Wielkość $p_{ij}^{(n)}$ oznacza prawdopodobieństwo przejścia ze stanu $i$ do stanu $j$ w dokładnie $n$ krokach.
\end{Def}

Zauważmy, że $p_{ij}^{(1)} = p_{ij}$ (przejście w jednym kroku) oraz $p_{ij}^{(0)} = \delta_{ij}$ (symbol Kroneckera), gdzie $\delta_{ij} = 1$ jeśli $i = j$ i $\delta_{ij} = 0$ w przeciwnym przypadku.

\begin{Tw}[Równania Chapmana-Kołmogorowa]
Dla łańcucha Markowa ze zbiorem stanów $S$ i dowolnych $m, n \geq 0$ oraz $i, j \in S$ zachodzi:
$$p_{ij}^{(m+n)} = \sum_{k \in S} p_{ik}^{(m)} p_{kj}^{(n)}$$
\end{Tw}

\begin{Dow}
Korzystając z własności Markowa i wzoru na prawdopodobieństwo całkowite:
\begin{align}
p_{ij}^{(m+n)} &= P(X_{m+n} = j | X_0 = i) \\
&= \sum_{k \in S} P(X_{m+n} = j | X_m = k, X_0 = i) P(X_m = k | X_0 = i) \\
&= \sum_{k \in S} P(X_{m+n} = j | X_m = k) P(X_m = k | X_0 = i) \\
&= \sum_{k \in S} p_{kj}^{(n)} p_{ik}^{(m)}
\end{align}
gdzie w trzecim przejściu wykorzystaliśmy własność Markowa.
\end{Dow}

\textbf{Interpretacja macierzowa:} Równania Chapmana-Kołmogorowa oznaczają, że macierz prawdopodobieństw przejścia w $n$ krokach jest równa $n$-tej potędze macierzy przejścia:
$$P^{(n)} = (p_{ij}^{(n)})_{i,j \in S} = P^n$$

\subsection{Grafy przejścia}

Graficzną reprezentacją łańcucha Markowa jest graf przejścia, który pozwala na intuicyjne zrozumienie struktury procesu.

\begin{Def}[Graf przejścia]
Graf przejścia łańcucha Markowa to graf skierowany $G = (V, E)$, gdzie:
\begin{itemize}
    \item $V = S$ (wierzchołki odpowiadają stanom),
    \item $(i, j) \in E$ wtedy i tylko wtedy, gdy $p_{ij} > 0$ (krawędź istnieje, gdy przejście jest możliwe).
\end{itemize}
Każda krawędź $(i, j)$ jest etykietowana prawdopodobieństwem $p_{ij}$.
\end{Def}


\begin{Prz}[Spacer losowy z barierami odbijającymi]
Rozważmy spacer losowy na zbiorze $\{0, 1, 2, 3, 4\}$ z barierami odbijającymi na końcach. Cząstka w stanie 0 zawsze przechodzi do stanu 1, w stanie 4 zawsze do stanu 3, a w stanach wewnętrznych przechodzi w prawo z prawdopodobieństwem $p = 0.6$ i w lewo z prawdopodobieństwem $q = 0.4$.

Macierz przejścia:
$$P = \begin{pmatrix}
0 & 1 & 0 & 0 & 0 \\
0.4 & 0 & 0.6 & 0 & 0 \\
0 & 0.4 & 0 & 0.6 & 0 \\
0 & 0 & 0.4 & 0 & 0.6 \\
0 & 0 & 0 & 1 & 0
\end{pmatrix}$$

Graf przejścia:

\begin{center}
\begin{tikzpicture}[node distance=2.5cm, every node/.style={circle, draw, minimum size=1cm}]
    \node (0) {0};
    \node (1) [right of=0] {1};
    \node (2) [right of=1] {2};
    \node (3) [right of=2] {3};
    \node (4) [right of=3] {4};
    
    \draw [->, bend left=15] (0) to node[above] {1} (1);
    \draw [->, bend left=15] (1) to node[above] {0.6} (2);
    \draw [->, bend left=15] (1) to node[below] {0.4} (0);
    \draw [->, bend left=15] (2) to node[above] {0.6} (3);
    \draw [->, bend left=15] (2) to node[below] {0.4} (1);
    \draw [->, bend left=15] (3) to node[above] {0.6} (4);
    \draw [->, bend left=15] (3) to node[below] {0.4} (2);
    \draw [->, bend left=15] (4) to node[below] {1} (3);
\end{tikzpicture}
\end{center}
\end{Prz}




\printbibliography

\end{document}